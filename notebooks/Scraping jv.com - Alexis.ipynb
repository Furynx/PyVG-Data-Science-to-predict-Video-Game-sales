{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7287ca",
   "metadata": {},
   "source": [
    "# PyVG: Data Science to predict Video Games sales\n",
    ">Equipe: Alexis Terrasse, Henri-François Mole, Hsan Drissi, Stephane Lelievre\n",
    ">\n",
    ">Promo: DS_Oct21\n",
    "---\n",
    "## Scraping JV.com - Alexis\n",
    "<img src='https://image.jeuxvideo.com/medias-md/145432/1454322894-3281-card.png' width=500></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a518b4",
   "metadata": {},
   "source": [
    "### Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7519b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Importation de BeautifulSoup\n",
    "import requests # Importation de requests\n",
    "from time import sleep # Importation de sleep\n",
    "import datetime # Importation de datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np # Importation de Numpy sous l'alias np\n",
    "import pandas as pd # Importation de Pandas sous l'alias pd\n",
    "import os # Importation de os\n",
    "\n",
    "import warnings # Import de warnings - gestion des avertissements\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chargement de Selenium et paramètrage des arguments\n",
    "from selenium import webdriver\n",
    "options= webdriver.ChromeOptions()\n",
    "options.add_argument('-headless')\n",
    "options.add_argument('-no-sandbox')\n",
    "options.add_argument('-disable-dev-shm-usage')\n",
    "driver= webdriver.Chrome('C:\\chromedriver.exe',options=options) # A adapter en fonction de l'emplacement de chromedriver.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b2ccd",
   "metadata": {},
   "source": [
    "### Définition de fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af95ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "###### Fonction de récupération des données des commentaires  #######\n",
    "#####################################################################\n",
    "\n",
    "def retrieve_user_reviews(url):\n",
    "    \n",
    "    month_fr= ['janv.','févr.','mars','avr.','mai','juin','juil','août','sept.','oct.','nov.','déc.']\n",
    "    \n",
    "    user_n=[] # On y stockera le nom de l'utilisateur de la critique\n",
    "    user_d=[] # On y stockera la date de la critique\n",
    "    user_s=[] # On y stockera le score de la critique\n",
    "    user_c=[] # On y stockera le texte de la critique\n",
    "\n",
    "    headermap = {\"User-Agent\": \"Mac Firefox\"};\n",
    "    markup = requests.get(url, headers=headermap).text\n",
    "    soup= BeautifulSoup(markup,\"lxml\")\n",
    "    n_pages= int(len(soup.select('.bloc-liste-num-page .lien-jv'))/2 + 1) #nb de pages de reviews ( len/2 )\n",
    "    \n",
    "    n_reviews= int(soup.select('.nb-total-avis')[0].text[:-5])\n",
    "    if n_reviews == 1: start_r= 1\n",
    "    else : start_r= 2\n",
    "        \n",
    "    for n in soup.select('.bloc-pseudo-avis')[start_r:]:\n",
    "        user_n.append(n.text.strip())\n",
    "                \n",
    "    for n in soup.select('.bloc-date-avis')[start_r:]:\n",
    "        if 'Posté hier' in n.text:\n",
    "            date=datetime.date.today()-datetime.timedelta(1)\n",
    "            user_d.append(str(date.day)+' '+month_fr[date.month-1]+str(date.year))\n",
    "        elif 'il y a' in n.text:\n",
    "            date = datetime.datetime.today()\n",
    "            user_d.append(str(date.day)+' '+month_fr[date.month-1]+str(date.year))\n",
    "        else: \n",
    "            if len(n.text) > 27 :\n",
    "                user_d.append(n.text.strip()[10:-8])\n",
    "            else: \n",
    "                date= datetime.date.today()\n",
    "                user_d.append(n.text[10: -8]+str(date.year))\n",
    "                \n",
    "    for n in soup.select('.note-avis strong')[start_r:]:\n",
    "        user_s.append(n.text.strip())\n",
    "        \n",
    "    for n in soup.select('.text-enrichi-forum')[start_r:]:\n",
    "        user_c.append(n.text.strip())      \n",
    "        \n",
    "    if n_pages > 1:\n",
    "        for p in range(2, n_pages+1):\n",
    "            url_p= url+'?p='+str(p)\n",
    "            markup = requests.get(url_p, headers=headermap).text\n",
    "            soup= BeautifulSoup(markup,\"lxml\")\n",
    "            \n",
    "            for n in soup.select('.text-user')[start_r:]:\n",
    "                user_n.append(n.text)\n",
    "                \n",
    "            for n in soup.select('.bloc-date-avis')[start_r:]:\n",
    "                if 'Posté hier' in n.text: \n",
    "                    date=datetime.date.today()-datetime.timedelta(1)\n",
    "                    user_d.append(str(date.day)+' '+month_fr[date.month-1]+str(date.year))\n",
    "                elif 'il y a' in n.text:\n",
    "                    date = datetime.datetime.today()\n",
    "                    user_d.append(str(date.day)+' '+month_fr[date.month-1]+str(date.year))\n",
    "                else: \n",
    "                    if len(n.text) > 27 :\n",
    "                        user_d.append(n.text.strip()[10:-8])\n",
    "                    else: \n",
    "                        date= datetime.date.today()\n",
    "                        user_d.append(n.text[10: -8]+str(date.year))\n",
    "                    \n",
    "            for n in soup.select('.note-avis strong')[start_r:]:\n",
    "                user_s.append(n.text.strip())\n",
    "                \n",
    "            for n in soup.select('.text-enrichi-forum')[start_r:]:\n",
    "                user_c.append(n.text.strip())\n",
    "                \n",
    "    # On retourne les listes contenant les noms, les dates, les scores et le commentaires des reviews            \n",
    "    return([user_n,user_d,user_s,user_c]) \n",
    "\n",
    "#####################################################################\n",
    "########## Fonction de récupération des données du jeu  #############\n",
    "#####################################################################\n",
    "\n",
    "def retrieve_game_infos(url):    \n",
    " \n",
    "    game_p=[]\n",
    "    users_reviews=[]\n",
    "\n",
    "    headermap = {\"User-Agent\": \"Mac Firefox\"};\n",
    "    markup = requests.get(url, headers=headermap).text\n",
    "    soup= BeautifulSoup(markup,\"lxml\")\n",
    "    \n",
    "    if soup.select('.gameHeaderBanner__title') == []: \n",
    "        title= soup.select('.articleHeader__title')[0].text[6:] # On stocke le nom du jeu\n",
    "        game_t=title.split(' :')[0]\n",
    "    else: game_t= soup.select('.gameHeaderBanner__title')[0].text # On stocke le nom du jeu\n",
    "    \n",
    "    if soup.select('.gameHeaderBanner__platformLink') != []:\n",
    "        for elt in soup.select('.gameHeaderBanner__platformLink'):\n",
    "            game_p.append(elt.text.strip()) # On stock la/les plateforme(s)  \n",
    "        if 'Tout support' in game_p : game_p.remove('Tout support') \n",
    "        if len(game_p) > 1: game_p= ', '.join(game_p)\n",
    "        else : game_p= game_p[0]\n",
    "    else: game_p=[]\n",
    "    \n",
    "    game_rscore= soup.select('.bloc-avis-testeur strong')[0].text # On stocke la note rédac\n",
    "    \n",
    "    if len(soup.select('.bloc-avis-lecteur strong')) == 0 : \n",
    "        game_uscore= np.nan  # NaN s'il n'y a pas de score lecteur\n",
    "        len_usereview= 0\n",
    "    else : \n",
    "        game_uscore= soup.select('.bloc-avis-lecteur strong')[0].text # On stocke le score lecteur\n",
    "        \n",
    "        driver= webdriver.Chrome('C:\\chromedriver.exe',options=options)\n",
    "        driver.get(url);\n",
    "        sleep(3)\n",
    "        element= driver.find_elements_by_xpath('/html/body/div[3]/div[4]/div/div[2]/div[3]/div/div[2]/div[2]/a[1]')\n",
    "        attrs = driver.execute_script('var items = {}; for (index = 0; index < arguments[0].attributes.length; ++index) { items[arguments[0].attributes[index].name] = arguments[0].attributes[index].value }; return items;', element[0])\n",
    "        users_reviews= retrieve_user_reviews('https://www.jeuxvideo.com/'+attrs['href'])    \n",
    "        len_usereview= len(users_reviews[0])\n",
    "    \n",
    "    if soup.select('.reviewText') != []:\n",
    "        game_rreview= soup.select('.reviewText')[0].text # #review rédac\n",
    "    else : game_rreview= np.nan\n",
    "    \n",
    "    # On retourne le titre, la/les plateformes, le score jv.com, le score utilsateur moyen, les critiques utilisateurs et le nb de critiques utilisateurs \n",
    "    return(game_t, game_p, game_rscore, game_uscore, users_reviews, len_usereview)\n",
    "\n",
    "\n",
    "###############################################################\n",
    "########## Fonction de parcours des tests de jeu  #############\n",
    "###############################################################\n",
    "\n",
    "def scraping_tests_page(end_p,start_p):    \n",
    "\n",
    "    df= pd.DataFrame(columns= ['Name','Platform','Critic_Score','User_Score','N_usereviews'])\n",
    "    df_reviews= pd.DataFrame(columns= ['Name', 'Platform','Date_crit', 'Name_crit','Score_crit','Comment_crit'])\n",
    "    driver= webdriver.Chrome('C:\\chromedriver.exe',options=options)\n",
    "    \n",
    "    npages= 935 # Nombre de pages de test \n",
    "    \n",
    "    for p in tqdm(range(end_p,start_p-1,-1)) :\n",
    "\n",
    "        name=[]\n",
    "        platform=[]\n",
    "        rscore=[]\n",
    "        uscore=[]\n",
    "        ureview=[]\n",
    "        len_ureview=[]\n",
    "        \n",
    "        url= 'https://www.jeuxvideo.com/tests/?p='+str(p)\n",
    "        #print(url)\n",
    "        driver.get(url)\n",
    "        elems = driver.find_elements_by_xpath(\"//a[@href]\") \n",
    "        \n",
    "        check= False        \n",
    "        for elem in elems:\n",
    "\n",
    "            if check == True :\n",
    "                if ('https://www.jeuxvideo.com/tests/?p=' in elem.get_attribute(\"href\")) or ('https://www.jeuxvideo.com/tests.htm' in elem.get_attribute(\"href\")):\n",
    "                    break\n",
    "                else: \n",
    "                    if ('https://www.jeuxvideo.com/test/' in elem.get_attribute(\"href\")) or ('https://www.jeuxvideo.com/articles/' in elem.get_attribute(\"href\")):\n",
    "                        #print(elem.get_attribute(\"href\"))\n",
    "                        game_t, game_p, game_rscore, game_uscore, users_reviews, len_usereview= retrieve_game_infos(elem.get_attribute(\"href\"))\n",
    "                        name.append(game_t)\n",
    "                        platform.append(game_p)\n",
    "                        rscore.append(game_rscore)\n",
    "                        uscore.append(game_uscore)\n",
    "                        ureview.append(users_reviews)\n",
    "                        len_ureview.append(len_usereview)            \n",
    "                                               \n",
    "            if elem.get_attribute(\"href\") == 'https://www.jeuxvideo.com/tests/titre/':\n",
    "                check= True     \n",
    "\n",
    "        columns = {\n",
    "            'Name': name,\n",
    "            'Platform': platform,\n",
    "            'Critic_Score': rscore,\n",
    "            'User_Score': uscore,\n",
    "            'N_usereviews': len_ureview}  \n",
    "\n",
    "        df_p= pd.DataFrame(columns)\n",
    "        df= pd.concat([df,df_p])\n",
    "\n",
    " \n",
    "\n",
    "        df_reviews_p= pd.DataFrame({}, columns= ['Name', 'Platform','Date_crit', 'Name_crit','Score_crit','Comment_crit'])\n",
    "        \n",
    "        k=0\n",
    "        for i in range(0,len(name)):#len(name)\n",
    "            for j in range(0,len_ureview[i]):\n",
    "                df_reviews_p.loc[k]= [name[i], platform[i], ureview[i][1][j], ureview[i][0][j], ureview[i][2][j], ureview[i][3][j]]\n",
    "                k+=1                    \n",
    "            k+=1\n",
    "\n",
    "        df_reviews= pd.concat([df_reviews, df_reviews_p])\n",
    "        \n",
    "    # Génere un .csv avec les données pour chaque jeux de la page examinée\n",
    "    file_name='jvcom_'+str(start_p)+'_'+str(end_p)+'.csv'\n",
    "    df.to_csv(file_name, sep=\",\", encoding='utf-8', index=False)\n",
    "        \n",
    "    # Génere un csv pour les critiques de chaque jeu de la page examinée  \n",
    "    file_name= 'jvcom_review_'+str(start_p)+'_'+str(end_p)+'.csv'        \n",
    "    df_reviews.to_csv(file_name, sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5026109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [1:18:56<00:00, 236.82s/it]\n",
      "100%|██████████| 20/20 [1:01:30<00:00, 184.52s/it]\n",
      "100%|██████████| 20/20 [1:21:41<00:00, 245.06s/it]\n",
      "100%|██████████| 20/20 [1:27:46<00:00, 263.35s/it]\n",
      "100%|██████████| 20/20 [1:30:44<00:00, 272.21s/it]\n",
      "100%|██████████| 20/20 [1:21:14<00:00, 243.71s/it]\n",
      "100%|██████████| 15/15 [55:11<00:00, 220.75s/it]\n"
     ]
    }
   ],
   "source": [
    "#On parcours l'intégralité des pages à rebours\n",
    "end=935\n",
    "start= end-19\n",
    "check= True\n",
    "while end > 0:\n",
    "    \n",
    "    check_file= 'jvcom_review_'+str(start)+'_'+str(end)+'.csv'\n",
    "    \n",
    "    # Si le fichier csv n'existe déjà on pas commence le scraping\n",
    "    if os.path.exists(check_file) == False:\n",
    "        scraping_tests_page(end,start)\n",
    "    \n",
    "    if (start -19 <= 0 ) & check:\n",
    "        end=start-1\n",
    "        start=1\n",
    "        check=False\n",
    "\n",
    "    else :\n",
    "        end-=20\n",
    "        start=end-19\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
